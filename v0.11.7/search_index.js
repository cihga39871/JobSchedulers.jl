var documenterSearchIndex = {"docs":
[{"location":"overhead/#Overhead-Test-of-Scheduling-Systems","page":"Overhead Benchmark","title":"Overhead Test of Scheduling Systems","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"To test the overhead of scheduling systems, I compared Base.Threads, Dagger.jl, and JobSchedulers using tiny tasks (x::Int += y::Int).","category":"page"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"warning: Warning\nx += y is not thread-safe, and it is for overhead test only. BenchmarkTools.jl cannot be used in this case because it competes scheduling systems.","category":"page"},{"location":"overhead/#System-information","page":"Overhead Benchmark","title":"System information","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"Julia v1.11.3 with -t 24,1 (24 threads in the default thread pool, and 1 interactive thread).\nEach script run on seperate Julia sessions.\nJobSchedulers.jl v0.11.6; Dagger v0.18.14.\nUbuntu 22.04 system.\nCPU: i9-13900K.\nMemory: 196GB DDR5 4800 MT/s.","category":"page"},{"location":"overhead/#Scripts","page":"Overhead Benchmark","title":"Scripts","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"The following scripts are used to test overhead of scheduling systems.","category":"page"},{"location":"overhead/#overhead-baseline.jl","page":"Overhead Benchmark","title":"overhead-baseline.jl","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"using .Threads\nfunction experiments_threads(a, K=10000)\n    x = 0\n    Threads.@threads for i in 1:K\n        x += a\n    end\n    x\nend\n\n# compile\nexperiments_threads(1, 10)\n\n# test\n@time experiments_threads(1, 10000);\n@time experiments_threads(1, 10000);\n@time experiments_threads(1, 10000);\n#   0.000267 seconds (9.61 k allocations: 160.906 KiB)\n#   0.000244 seconds (8.87 k allocations: 149.297 KiB)\n#   0.000186 seconds (9.35 k allocations: 156.750 KiB)\n\n@time experiments_threads(1, 100000);\n@time experiments_threads(1, 100000);\n@time experiments_threads(1, 100000);\n#   0.001288 seconds (98.01 k allocations: 1.506 MiB)\n#   0.001620 seconds (99.14 k allocations: 1.523 MiB)\n#   0.001470 seconds (99.61 k allocations: 1.530 MiB)","category":"page"},{"location":"overhead/#overhead-jobschedulers.jl","page":"Overhead Benchmark","title":"overhead-jobschedulers.jl","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"using JobSchedulers\n\nfunction experiments_jobschedulers(a, K=10000)\n    x = 0\n    f() = x += a\n    for i in 1:K\n        submit!(f)\n    end\n    wait_queue()\n    x\nend\n\n# compile\nexperiments_jobschedulers(1, 10)\n\n# test\n@time experiments_jobschedulers(1, 10000);\n@time experiments_jobschedulers(1, 10000);\n@time experiments_jobschedulers(1, 10000);\n#  0.007719 seconds (170.36 k allocations: 10.767 MiB, 197 lock conflicts)\n#  0.007741 seconds (159.35 k allocations: 10.566 MiB, 198 lock conflicts)\n#  0.010097 seconds (157.05 k allocations: 10.524 MiB, 14.18% gc time, 70 lock conflicts)\n\n@time experiments_jobschedulers(1, 100000);\n@time experiments_jobschedulers(1, 100000);\n@time experiments_jobschedulers(1, 100000);\n#  0.119578 seconds (1.57 M allocations: 105.162 MiB, 30.19% gc time, 2344 lock conflicts)\n#  0.122050 seconds (1.56 M allocations: 105.044 MiB, 37.64% gc time, 2216 lock conflicts)\n#  0.113245 seconds (1.56 M allocations: 105.055 MiB, 33.09% gc time, 2205 lock conflicts)","category":"page"},{"location":"overhead/#overhead-dagger.jl","page":"Overhead Benchmark","title":"overhead-dagger.jl","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"using Dagger\nfunction experiments_dagger(a, K=10000)\n    x = 0\n    f() = x += a\n    @sync for i in 1:K\n        Dagger.@spawn f()\n    end\n    x\nend\n\n# compile\nexperiments_dagger(1, 10)\n\n# test\n@time experiments_dagger(1, 10000);\n@time experiments_dagger(1, 10000);\n@time experiments_dagger(1, 10000);\n#   1.097989 seconds (31.55 M allocations: 2.315 GiB, 33.66% gc time, 761375 lock conflicts)\n#   1.314606 seconds (27.20 M allocations: 1.944 GiB, 33.19% gc time, 622269 lock conflicts)\n#   1.121939 seconds (30.54 M allocations: 2.227 GiB, 32.63% gc time, 738192 lock conflicts)\n\n@time experiments_dagger(1, 100000);\n@time experiments_dagger(1, 100000);\n@time experiments_dagger(1, 100000);\n#  11.078450 seconds (305.29 M allocations: 22.357 GiB, 36.32% gc time, 7429201 lock conflicts)\n#  12.931351 seconds (316.35 M allocations: 23.249 GiB, 35.22% gc time, 7587318 lock conflicts)\n#  11.318478 seconds (121.07 M allocations: 7.953 GiB, 22.46% gc time, 1476778 lock conflicts, 0.04% compilation time)","category":"page"},{"location":"overhead/#Results","page":"Overhead Benchmark","title":"Results","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"Table. Benchmark of average elapsed time to schedule 10,000 and 100,000 tasks using different scheduling systems.","category":"page"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"Modules 10,000 Tasks 100,000 Tasks\nBase.Threads 0.000232 s 0.001459 s\nJobSchedulers 0.008519 s 0.118291 s\nDagger 1.178178 s 11.776093 s","category":"page"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"JobSchedulers.jl can schedule 10,000 tasks within 0.01 second, which is 150X faster than Dagger.\nJobSchedulers.jl is robust, and able to achive a decent speed when scaling up to 100,000 tasks.","category":"page"},{"location":"overhead/#Conclusions","page":"Overhead Benchmark","title":"Conclusions","text":"","category":"section"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"JobSchedulers.jl has very little overhead when comparing with Base.Threads, but provides strong extensive features than Base.Threads.","category":"page"},{"location":"overhead/","page":"Overhead Benchmark","title":"Overhead Benchmark","text":"The low overhead of JobSchedulers.jl makes it interchangable with Base.Threads.","category":"page"},{"location":"best_practice/#Best-Practice-(Please-Read)","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"","category":"section"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"In the following sections, we briefly go through a few techniques that can help you understand tricks when using JobSchedulers.","category":"page"},{"location":"best_practice/#Multi-threaded-or-single-threaded-Julia-session","page":"Best Practice (Please Read)","title":"Multi-threaded or single-threaded Julia session","text":"","category":"section"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"It is recommended to use JobSchedulers in multi-threaded Julia sessions. ","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"Jobs are controlled using a main scheduler task (JobSchedulers.SCHEDULER_TASK[]). This task always binds to thread ID (tid) 1 and does not migrate to other threads. During initiation, JobSchedulers.jl checks available tids in the default thread pool. If the default thread pool is empty after excluding tid 1, JobSchedulers.jl will use a single-thread mode (JobSchedulers.SINGLE_THREAD_MODE[]). Otherwise, JobSchedulers.jl will use a multi-thread mode.","category":"page"},{"location":"best_practice/#Single-thread-Mode","page":"Best Practice (Please Read)","title":"Single-thread Mode","text":"","category":"section"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"The maximum number of CPU is default to the system CPU (Sys.CPU_THREADS). ","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"All Jobs are migratable, and they might yield to other tasks. ","category":"page"},{"location":"best_practice/#Multi-thread-Mode","page":"Best Practice (Please Read)","title":"Multi-thread Mode","text":"","category":"section"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"The maximum number of CPU is default to","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"number of threads in the default thread pool, if you use any interactive threads. (ie. starting julia with -t 10,1.)\nnumber of threads in the default thread pool minus 1, if you do not use interactive threads. (ie. starting julia with -t 10.)","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"The tids that JobScheduler.jl can use are stored in a Channel JobSchedulers.THREAD_POOL[]. ","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"If you submit a job assigning ncpu > 0, ","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"the job does not migrate to other threads. \nAlso, if you only use JobSchedulers to schedule tasks, your tasks will not be blocked by other tasks at any time. It is important when your tasks need quick response (like a web API server). Therefore, you can ignore the existance of interactive threads when using JobSchedulers.jl.\ninfo: Info\nJobSchedulers.jl even solves the issue of interactive tasks prior to the official Julia introducing task migration (partially solved) and the interactive/default thread pools.","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"If you set ncpu = 0 to your job,","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"the job is migratable and does not take any tid from JobSchedulers.THREAD_POOL[].\ntip: Tip\nUse ncpu = 0 only when a job is very small, or a job that spawns and waits for other jobs:using JobSchedulers\n\nsmall_job = Job(ncpu = 0) do\n    # within the small job,\n    # submit 100 big jobs\n    big_jobs = map(1:100) do _\n        @submit ncpu=1 sum(rand(9999999))\n    end\n    # post-process of big jobs\n    total = 0.0\n    for j in big_jobs\n        total += fetch(j)\n    end\n    total\nend\nsubmit!(small_job)\ntotal = fetch(small_job)\n# 4.999998913757924e8","category":"page"},{"location":"best_practice/#Avoid-simultaneous-use-of-Job-and-other-multi-threaded-methods-using-the-:default-thread-pool","page":"Best Practice (Please Read)","title":"Avoid simultaneous use of Job and other multi-threaded methods using the :default thread pool","text":"","category":"section"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"Since a normal Job binds to a tid in the default thread pool and does not migrate, it is better not to simultaneously use Job and other threaded methods, such as Threads.@spawn and Threads.@threads. ","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"Also, JobScheduers.jl has very low extra computational costs (scheduling 10,000 jobs within 0.01 second), so normal threaded methods can be replaced with Job.","category":"page"},{"location":"best_practice/","page":"Best Practice (Please Read)","title":"Best Practice (Please Read)","text":"If you really want to use both Job and other threaded methods, it is better to make sure to run them at different time. You may use wait_queue(), scheduler_stop(), and scheduler_start() in this situation.","category":"page"},{"location":"changelog/#Changelog","page":"Change Log","title":"Changelog","text":"","category":"section"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.7","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: are_remaining_jobs_more_than(x) not always return a Bool, which causes seg fault.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.6","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: append not defined when calling next_recur_job(::Job) and the job need IO redirection.\nOptim: better text/plain output for Job. If Job is failed, show error and stack trace.\nOptim: faster processing of showing job lists/vectors.\nOptim: linked list updates: Job now has internal _prev and _next fields to replace MutableLinkedList, which creates a node wrapper for each job in each list. Now saves a little bit memory.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.5","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Change/Optim: items in job.dependency will not be deleted when states meet. Use job._dep_check_id to store the next dependency id. Backup will remove job.dependency before storing a job.\nOrganize: new file job_state_change.jl takes some code from scheduler.jl.\nOptim: JobQueue uses linked list rather than vectors. It provides O(1) deletion speed, which is useful when a flood of jobs (>100,000) are submitted.\nOptim: remove unused dependendies.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"TODO:","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"JOB_QUEUE.queuing::SortedDict{Int,Vector{Job},Base.Order.ForwardOrdering}: change Vector{Job} to a certain type that can group same condition (ncpu, mem), to avoid greedy search all jobs in JOB_QUEUE.queuing when ncpu and mem not met for all queuing jobs.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.4","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compat: Julia v1.12: t::Task._state is atomic now.\nCompat: Julia v1.12: nthreads() now may not represent tids. Use other methods to get tids of default thread pool.\nChange: Only use default thread pool for Jobs with ncpu >= 1. Interactive thread pools are ignored. In previous versions, JobSchedulers use both interactive and default pools.\nChange: VERSION check now use VERSION >= v\"x.y-\", rather than VERSION >= v\"x.y\". The former is evaluated to true for v\"1.12.0-DEV.1234\", while latter is false.\nChange: JOB_ID[] += rand(20000:40000), rather than adding 1: hard to predict ID using rand increment, in case some apps may allow users query job ID. Comments: the best practice for app developers is not directly expose job IDs, or use additional methods to constrain queries.\nFix: set_scheduler_max_mem(): warning message's if statement: use mem > Sys.total_memory() * 0.9 + 1, rather than mem > Sys.total_memory() * 0.9.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.3","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: Job with Cmd and add tests. (#18)","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.2","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feat: add check for dependencies' job states when creating Job. Throw error immediately when invalid job state is found.\nChange: Base.show(io::IO, job::Job) prints better job's description.\nFix: 32-bit system: convert_dependency and convert_dependency_element did not include all possible types.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.1","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compat: 32-bit system.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.11.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix and compat: Cron has been rewritten based on the standard crontab, including its bug described here.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.7","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: crash when showing progress meter after all jobs finished while stdout/sterr are redirected to files. Remove call to legacy queue_summary, which was replaced a while ago. ","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.6","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: is_dependency_ok(job): capture job.state in variable to avoid changing when running the function, which might lead to error.\nPerformance: job: when user's function is done, change the state to done or failed within job.task, and update_queue!() can capture this change now. In previous versions, if a job is done, the flag might not updated to done, which cause significant delay in some situations.\nChange: scheduler_reactivation interval changed to  0.1s from 0.5s.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.5","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: when showing progress meter, changing JobGroup.x was not thread safe. \nFix: when showing progress meter, now CPU and MEM was not computed again from JobGroup, but just fetch from a global variable RESOURCE(cpu, mem)::Resource. RESOURCE is computed when update_queue!()","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.4","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Optimize: remove extra scheduler_status check in queue_progress(...).\nOptimize: wait_queue(show_progress=false) no longer took 100% CPU. Now it computes exit condition only when scheduler updates.\nChange: explicit error when calling the second wait_queue(...). Only one is allowed each time. \nCompat: JLD2 0.5.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.3","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: error when calling wait_queue(;show_progress=true) and no job has been submitted.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.2","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feat: new macro @submit to create a job using an expression. It will automatically add explictly referred Job dependencies by walking through the symbols in the expression.\nFeat: new method fetch.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.1","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: job not defined if Job failed.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.10.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feat/Optimize: Rewriting scheduler for 200~400X speed up. Scheduling 100,000 small tasks in 0.2 seconds using 24 threads.\nDeprecate: SCHEDULER_UPDATE_SECOND and set_scheduler_update_second() are no longer required. Changing them will have no effect on the scheduler.\nFeat: Now, the scheduler updates when needed, and every 0.5 second. When specific events happen, scheduler_need_action() is used to trigger update of the scheduler. SCHEDULER_REACTIVATION_TASK[] is used to trigger scheduler_need_action() every 0.5 second because a regular check is needed for future jobs (defined by j::Job.schedule_time).\nChange: Job's fields stdout_file::String and stderr_file::String is changed to stdout::Union{IO,AbstractString,Nothing} and stderr::Union{IO,AbstractString,Nothing}.\nChange: remove function format_stdxxx_file(x).\nOptimize: check whether a job needs IO redirection before wrapping in task. Also, avoid unecessary stack when wrapping a new job, avoiding recurring job's stack overflow due to creating new jobs.\nFeat: Now people can set_group_seperator(group_seperator::Regex=r\": *\"). A group name will be given to Job. It is useful when showing progress meters.\nFeat: New wait(j::Job) and wait(js::Vector{Job}).\nOptimize: progress bar now does not blink: now we do not clear lines before printing. Instead, printing a \"erase from cursor to end of line\" characters.\nOptimize: rewrite progress computing for much faster speed.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.9.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Change: ncpu now also accepts Float64, but if 0 < ncpu < 1, job still binds to one thread and other jobs cannot use binded threads.\nChange: Job's field name :create_time is changed to :submit_time.\nChange: check duplicate job when submitting: check submit_time == DateTime(0), rather than recursively check existing jobs in JOB_QUEUE.\nFeat: showing queue() is better.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.8.4","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Update: remove print-to-stdout statements during precompilation.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.8.3","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compat: fix precompilation runs forever in Julia v1.10.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.8.2","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feat: not replace Base.istaskfailed. Use istaskfailed2 instead.\nFeat: recurring job: job does not immediately after submit, except manually set Job(..., schedule_time). (#8)\nFeat: no double printing stacktrace when a job failed. \nFeat: progress bar: dim job count == 0. (#9)","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.8.1","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: scheduler() handles errors and InteruptExceptions more wisely. (Thanks to @fivegrant, #7)","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.8.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feat: ncpu == 0 can set to a Job, but a warning message shows.\nFeat: dependency = DONE => job_A: to be simplified to dependency = job_A or dependency = job_A.id.\nFeat: Simplify Job() methods.\nFeat: submit!(Job(...)): to be simplified to submit!(...).\nFeat: schedule repetitive jobs using Cron until a specific date and time: Job(cron = Cron(0,0,*,*,*,*), until = Year(1)). It is  inspired by Linux-based crontab.\nChange: Job(): default wall time value increase to Year(1) from Week(1).\nChange: SCHEDULER_TASK is now a Base.RefValue{Task} rather than undefined or Task.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.12","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compat: Pipelines v0.9, 0.10 (new), 1 (not published).\nDocs: Use Documenter.jl.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.11","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Update: Term to v2.\nFeat: Set a lower loop interval of nthreads > 2.\nFeat: Move scheduler_start() in __init__().","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.10","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feature: Better progress bar for visualization.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.9","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: solve_optimized_ncpu(): devision by 0 if njob == 0.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.8","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feature: solve_optimized_ncpu(): Find the optimized number of CPU for a job.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.7","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: style_line(): index error for special UTF characters.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.6","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: if original stdout is a file, not contaminating stdout using wait_queue(show_progress = true).","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.5","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Change: remove extra blank lines after wait_queue(show_progress = true).\nFix a benign error (task switch error for sleep()).","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.4","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feature: Progress meter: wait_queue(show_progress = true).","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.3","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compat: Pipelines v0.9: significant improvement on decision of re-run: considering file change.\nFix: pretty print of Job and Vector{Job}.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.2","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: unexpected output of scheduler_status() when SCHEDULER_TASK is not defined.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.1","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compat: PrettyTables = \"0.12 - 2\" to satisfy DataFrames v1.3.5 which needs PrettyTables v1 but not v2.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.7.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Remove dependency DataFrames and change to PrettyTables. The loading time of DataFrames is high.\nFeature: now a Job is sticky to one thread (>1). JobSchedulers allocates and manuages it. The SCHEDULER_TASK is sticky to thread 1.\nFeature: queue(...) is rewritten.\nFeature: Better pretty print of Job and queue().\nFeature: New function: wait_queue() waits for all jobs in queue() become finished.\nFeature: New function: set_scheduler()\nFix: set_scheduler_max_cpu(percent::Float64): use default_ncpu() if error.\nChange: SCHEDULERUPDATESECOND to 0.05 from 0.6","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.12","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feature: Enchance compatibility with Pipelines v0.8.5: Program has a new field called arg_forward that is used to forward user-defined inputs/outputs to specific keyword arguments of JobSchedulers.Job(::Program, ...), including name::String, user::String, ncpu::Int, mem::Int.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.11","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: running queue() when updating queue: use lock within DataFrames.DataFrame(job_queue::Vector{Job}).","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.10","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Update documents.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.9","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Support Pipelines.jl v0.8.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.8","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feature: Replace @Job with Job to run program without creating inputs::Dict and outputs::Dict. Remove @Job.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.7","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Feature: Run program without creating inputs::Dict and outputs::Dict: @Job program::Program key_value_args... Job_args.... See also @run in Pipelines.jl.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.6","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Optimize: job.dependency now accepts DONE => job, [DONE => job1.id; PAST => job2].\nOptimize: is_dependency_ok(job::Job)::Bool is rewritten: for loop when found a dep not ok, and delete previous ok deps. If dep is provided as Int, query Int for job and then replace Int with the job.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.5","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: If an app is built, SCHEDULERMAXCPU and SCHEDULERMAXMEM will be fixed to the building computer: fix by re-defining SCHEDULER_MAX_CPU and SCHEDULER_MAX_MEM in __init__().\nDebug: add debug outputs.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.4","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: scheduler_stop() cannot stop because v0.6.1 update. Now scheduler_stop does not send ^C to SCHEDULER_TASK, but a new global variable SCHEDULER_WHILE_LOOP::Bool is added to control the while loop in scheduler().\nOptimize: the package now can be precompiled: global Task cannot be precompiled, so we do not define SCHEDULER_TASK::Task when loading the package. Define it only when needed.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.3","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: scheduler_start() now wait until SCHEDULER_TASK is actually started. Previously, it returns after schedule(SCHEDULER_TASK).","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.2","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compat Pipelines v0.7.0.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.1","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Robustness: scheduler() and waitforlock(): wrap sleep() within a try-catch block. If someone sends ctrl + C to sleep, scheduler wont stop.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.6.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compatibility: Pipelines v0.5.0: Job(...; dir=dir).","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.5.1","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Fix: programcloseio: If the current stdout/stderr is IO, restore to default stdout/stderr.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.5.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Compatibility: Pipelines v0.5.0: fixed redirection error and optimized stack trace display. Extend Base.istaskfailed to fit Pipelines and JobSchedulers packages, which will return a StackTraceVector in t.result, while Base considered it as :done. The fix checks the situation and modifies the real task status and other properties.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.4.1","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Export PAST. PAST is the super set of DONE, FAILED, CANCELLED, which means the job will not run in the future.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.4.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"If running with multi-threads Julia, SCHEDULER_TASK runs in thread 1, and other jobs spawn at other threads. Thread assignment was achieved by JobScheduler. Besides, SCHEDULER_MAX_CPU = nthreads() > 1 ? nthreads()-1 : Sys.CPU_THREADS.\nNew feature: queue(job_state::Symbol).\nUse try-finally for all locks.","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"v0.3.0","category":"page"},{"location":"changelog/","page":"Change Log","title":"Change Log","text":"Tasks run on different threads, if Julia version supports and nthreads() > 1.\nUse SpinLock.\nFix typo \"queuing\" from \"queueing\".\nNotify when a job is failed.","category":"page"},{"location":"manual/#Manual","page":"Manual","title":"Manual","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"JobSchedulers.jl can used to glue commands in a pipeline/workflow, and can also be used to schedule small Julia tasks. ","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"info: Multi-threading\nIt is recommended to start Julia with multi-threads when using JobSchedulers.jl.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"using JobSchedulers","category":"page"},{"location":"manual/#Create-a-Job","page":"Manual","title":"Create a Job","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"A Job is the wrapper of AbstractCmd, Function or Task:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"command_job = Job(\n    `echo command job done`    # AbstractCmd to run\n)\n\nfunction_job = Job() do  # the function should have no arguments\n    println(\"function job done\")\nend\n\ntask_job = Job(\n    @task(println(\"task job done\"))  # Task to run\n)\n\njob_with_args = Job(\n    @task(begin println(\"job_with_args done\"); \"result\" end); # Task to run\n    name = \"job with args\",     # Job name.\n    user = \"me\",                # Job owner.\n    ncpu = 1,                   # Number of CPU required.\n    mem = 1KB,                  # Number of memory required (unit: TB, GB, MB, KB, B).\n    schedule_time = Second(3),  # Run after 3 seconds; can be ::DateTime or ::Period.\n    wall_time = Hour(1),        # The maximum time to run the job. (Cancel job after reaching wall time.)\n    priority = 20,              # Lower number = higher priority.\n    dependency = [              # Defer job until some jobs reach some states.\n        command_job,\n        DONE => task_job\n    ]\n)\n# Job:\n#   id            → 8345846200460913\n#   name          → \"job with args\"\n#   user          → \"me\"\n#   ncpu          → 1.0\n#   mem           → 1.0 KB\n#   schedule_time → 22:18:45\n#   submit_time   → na\n#   start_time    → na\n#   stop_time     → na\n#   wall_time     → 1 hour\n#   cron          → Cron(:none)\n#   until         → forever\n#   state         → :queuing\n#   priority      → 20\n#   dependency    → 2 jobs\n#   task          → Task\n#   stdout        → nothing\n#   stderr        → nothing","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"dependency argument in Job controls when to start a job.It is a vector with element STATE => job or STATE => job.id.STATE is one of DONE, FAILED, CANCELLED, QUEUING, RUNNING, PAST.   The first 5 states are real job states.   PAST is the super set of DONE, FAILED, CANCELLED, which means the job will not run in the future.DONE => job can be simplified to job from v0.8.","category":"page"},{"location":"manual/#Submit-a-Job","page":"Manual","title":"Submit a Job","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Submit a job to queue:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"submit!(command_job)\nsubmit!(task_job)\nsubmit!(job_with_args)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Details: submit!","category":"page"},{"location":"manual/#Create-and-submit-a-Job","page":"Manual","title":"Create and submit a Job","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"submit!(Job(...)) can be simplified to submit!(...) from v0.8.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"job = submit!(@task(println(\"job\")), priority = 0)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Macro @submit [args...] expression is available from v0.10.2. It will automatically add explictly referred Job dependencies by walking through the symbols in the expression.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"job = @submit ncpu=1 1+1\n\njob_auto_dependency = @submit 1 + result(job)\n# equivalent to submit!(() -> 1 + result(job); dependency=job)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"@submit supports any type of Expression, including a code block:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"x = 5\njob_block = @submit begin\n    y = x + 1\n    y^2\nend\n@assert fetch(job_block) == (5+1)^2","category":"page"},{"location":"manual/#Get-a-Job's-Result","page":"Manual","title":"Get a Job's Result","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Get the returned result imediately. If job is not finished, show a warning message and return nothing:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"result(job)\n# \"result\"","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"You can also use fetch to wait for job to finish and return its result from JobSchedulers v0.10.2.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"fetch(job)","category":"page"},{"location":"manual/#Cancel-a-Job","page":"Manual","title":"Cancel a Job","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Interrupt or cancel! a job:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"cancel!(job)","category":"page"},{"location":"manual/#Recurring/repetitive-Job","page":"Manual","title":"Recurring/repetitive Job","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Recurring jobs can be defined using two arguments of Job: Job(..., cron::Cron, until::Union{DateTime,Period}).","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"cron::Cron use a similar syntax of Linux's Crontab. It accepts a Cron object. It extends Linux's crontab and allows repeat every XX seconds. You can use your favorate *, -, , syntax just like crontab. Other features please see Cron.\nuntil::Union{DateTime,Period}): stop job recurring until date and time.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Construction:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Cron(second, minute, hour, day_of_month, month, day_of_week)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Examples:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Cron()\n# Cron(every minute at 0 second past every hour everyday)\n\nCron(0,0,0,1,1,0)\nCron(:yearly)\nCron(:annually)\n# Cron(at 00:00:00 on day-of-month 1 in Jan)\n\nCron(0,0,0,1,*,*)\nCron(:monthly)\n# Cron(at 00:00:00 on day-of-month 1)\n\nCron(0,0,0,*,*,1)\nCron(:weekly)\n# Cron(at 00:00:00 on Mon)\n\nCron(0,0,0,*,'*',\"*\") # * is equivalent to '*', and \"*\" in Cron.\nCron(:daily)\nCron(:midnight)\n# Cron(at 00:00:00 everyday)\n\nCron(0,0,*,*,*,*)\nCron(:hourly)\n# Cron(at 0 minute, 0 second past every hour everyday)\n\nCron(0,0,0,0,0,0) # never repeat\nCron(:none)       # never repeat\n# Cron(:none)\n\nCron(0,0,0,*,*,\"*/2\")\n# Cron(at 00:00:00 on Tue, Thu and Sat)\n\nCron(0,0,0,*,*,\"1-7/2\")\n# Cron(at 00:00:00 on Mon, Wed, Fri and Sun)\n\nCron(0,0,0,1,\"1-12/3\",*)\n# Cron(at 00:00:00 on day-of-month 1 in Jan, Apr, Jul and Oct)\n\nCron(30,4,\"1,3-5\",1,*,*)\n# Cron(at 4 minute, 30 second past 1, 3, 4 and 5 hours on day-of-month 1)\n\n# repeatly print time every 5 seconds, until current time plus 20 seconds\nrecurring_job = submit!(cron = Cron(\"*/5\", *, *, *, *, *), until = Second(20)) do\n    println(now())\nend\n# 2025-03-04T22:26:00.176\n# 2025-03-04T22:26:05.077\n# 2025-03-04T22:26:10.089\n# 2025-03-04T22:26:15.051","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Details: Cron","category":"page"},{"location":"manual/#Queue","page":"Manual","title":"Queue","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Show all jobs:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"queue(:all)      # or:\nqueue(all=true)  # or:\nall_queue()\n# 1-element Vector{Job}:\n# ┌─────┬───────┬──────────────────┬─────────────────┬──────┬──────┬─────────\n# │ Row │ state │               id │            name │ user │ ncpu │    mem ⋯\n# ├─────┼───────┼──────────────────┼─────────────────┼──────┼──────┼─────────\n# │   1 │ :done │ 6407186212753787 │ \"job with args\" │ \"me\" │  1.0 │ 1.0 KB ⋯\n# └─────┴───────┴──────────────────┴─────────────────┴──────┴──────┴─────────\n#                                                           9 columns omitted","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"compat: Changes from v0.10\nBefore v0.10, all jobs will be saved to queue. However, from v0.10, unnamed jobs (job.name == \"\") will not be saved if they successfully ran. If you want to save unnamed jobs, you can set using JobSchedulers.destroy_unnamed_jobs_when_done(false).","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Show queue (running and queuing jobs only):","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"queue()\n# 0-element Vector{Job}:\n# ┌─────┬───────┬────┬──────┬──────┬──────┬─────┬──────────┬────────────┬────\n# │ Row │ state │ id │ name │ user │ ncpu │ mem │ priority │ dependency │ s ⋯\n# └─────┴───────┴────┴──────┴──────┴──────┴─────┴──────────┴────────────┴────\n#                                                           7 columns omitted","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Show queue using a job state (QUEUING, RUNNING, DONE, FAILED, CANCELLED, or PAST):","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"queue(DONE)\n# 1-element Vector{Job}:\n# ┌─────┬───────┬──────────────────┬─────────────────┬──────┬──────┬─────────\n# │ Row │ state │               id │            name │ user │ ncpu │    mem ⋯\n# ├─────┼───────┼──────────────────┼─────────────────┼──────┼──────┼─────────\n# │   1 │ :done │ 6407186212753787 │ \"job with args\" │ \"me\" │  1.0 │ 1.0 KB ⋯\n# └─────┴───────┴──────────────────┴─────────────────┴──────┴──────┴─────────\n#                                                           9 columns omitted","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Show queue using a String or Regex to match job name or user:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"queue(\"me\")\nqueue(\"with args\")\nqueue(r\"job.*\")\n# 1-element Vector{Job}:\n# ┌─────┬───────┬──────────────────┬─────────────────┬──────┬──────┬─────────\n# │ Row │ state │               id │            name │ user │ ncpu │    mem ⋯\n# ├─────┼───────┼──────────────────┼─────────────────┼──────┼──────┼─────────\n# │   1 │ :done │ 6407186212753787 │ \"job with args\" │ \"me\" │  1.0 │ 1.0 KB ⋯\n# └─────┴───────┴──────────────────┴─────────────────┴──────┴──────┴─────────\n#                                                           9 columns omitted","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"See more at queue, and all_queue.","category":"page"},{"location":"manual/#Job-query","page":"Manual","title":"Job query","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Get Job object by providing job ID, or access the index of queue:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"job_query(6407186212753787)  # or:\nqueue(6407186212753787)\nqueue(:all)[1]\n# Job:\n#   id            → 6407186212753787\n#   name          → \"job with args\"\n#   user          → \"me\"\n#   ncpu          → 1.0\n#   mem           → 1.0 KB\n#   schedule_time → 13:11:45\n#   submit_time   → 13:12:46\n#   start_time    → 13:12:46\n#   stop_time     → 13:12:46\n#   wall_time     → 1 hour\n#   cron          → Cron(:none)\n#   until         → forever\n#   state         → :done\n#   priority      → 20\n#   dependency    → 2 jobs\n#   task          → Task\n#   stdout        → nothing\n#   stderr        → nothing","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"See more at job_query, and queue.","category":"page"},{"location":"manual/#Wait-for-jobs-and-progress-meter","page":"Manual","title":"Wait for jobs and progress meter","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"wait for a specific job(s):","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"wait(j::Job)\nwait(js::Vector{Job})","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Wait for jobs finished using wait_queue.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"wait_queue()\n# no output\n\n# If `show_progress = true`, a fancy progress meter will display.\nwait_queue(show_progress = true)\n\n# stop waiting when <= 2 jobs are queuing or running.\nwait_queue(show_progress = true, exit_num_jobs = 2)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"(Image: progress meter)","category":"page"},{"location":"manual/#Scheduler-control","page":"Manual","title":"Scheduler control","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Scheduler is automatically started after v0.7.11.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"scheduler_stop()\n# [ Info: Scheduler task stops.\n# ┌ Warning: Scheduler reactivation task is not running.\n# └ @ JobSchedulers ~/projects/JobSchedulers.jl/src/control.jl:92\n\nscheduler_start()\n# ┌ Warning: Scheduler task was interrupted or done. Restart.\n# └ @ JobSchedulers ~/projects/JobSchedulers.jl/src/control.jl:61\n# ┌ Warning: Scheduler reactivation task was interrupted or done. Restart.\n# └ @ JobSchedulers ~/projects/JobSchedulers.jl/src/control.jl:61\n\nscheduler_status()\n# ┌ Info: Scheduler is running.\n# │   SCHEDULER_MAX_CPU = 23\n# │   SCHEDULER_MAX_MEM = \"169.7 GB\"\n# │   JOB_QUEUE.max_done = 10000\n# │   JOB_QUEUE.max_cancelled = 10000\n# │   SCHEDULER_TASK[] = Task (runnable) @0x00007d4160031dc0\n# └   SCHEDULER_REACTIVATION_TASK[] = Task (runnable) @0x00007d4160031f50\n# :running","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"info: Number of CPU Optimization\nJobSchedulers.jl also provide a function to find optimized ncpu that a Job can use, based on current cpu usage. See more at solve_optimized_ncpu.","category":"page"},{"location":"manual/#Compatibility-with-Pipelines.jl","page":"Manual","title":"Compatibility with Pipelines.jl","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Pipelines.jl: A lightweight Julia package for computational pipelines and workflows.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"You can also create a Job by using Program types from Pipelines.jl:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Job(p::Program; program_kwargs..., run_kwargs..., job_kwargs...)\nJob(p::Program, inputs; run_kwargs..., job_kwargs...)\nJob(p::Program, inputs, outputs; run_kwargs..., job_kwargs...)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"program_kwargs... is input and output arguments defined in p::Program.\nrun_kwargs... is keyword arguments of run(::Program; ...)\njob_kwargs... is keyword arguments of Job(::Union{Base.AbstractCmd,Task}; ...)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Details can be found by typing","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"julia> using Pipelines, JobSchedulers\njulia> ?run\njulia> ?Job","category":"page"},{"location":"manual/#Example","page":"Manual","title":"Example","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"using Pipelines, JobSchedulers\n\np = CmdProgram(\n    inputs = [\"IN1\", \"IN2\"],\n    outputs = \"OUT\",\n    cmd = pipeline(`echo inputs are: IN1 and IN2` & `echo outputs are: OUT`)\n)\n# CmdProgram:\n#   name             → Command Program\n#   id_file          → \n#   info_before      → auto\n#   info_after       → auto\n#   cmd_dependencies → <empty>\n#   arg_inputs       → IN1 :: Any (required)\n#                      IN2 :: Any (required)\n#   validate_inputs  → do_nothing\n#   prerequisites    → do_nothing\n#   cmd              → `echo inputs are: IN1 and IN2` & `echo outputs are: OUT`\n#   infer_outputs    → do_nothing\n#   arg_outputs      → OUT :: Any (required)\n#   validate_outputs → do_nothing\n#   wrap_up          → do_nothing\n#   arg_forward      → <empty>\n\n### native Pipelines.jl method to run the program\nrun(p, IN1 = `in1`, IN2 = 2, OUT = \"out\", touch_run_id_file = false) \n# touch_run_id_file = false means do not create a file which indicates \n# the job is done and avoids re-run.\n\n# ┌ Info: 2025-03-04 22:31:11 Started: Command Program\n# │   command_template = `echo inputs are: IN1 and IN2` & `echo outputs are: OUT`\n# │   run_id = Base.UUID(\"c30eed71-69ff-544b-a175-b6077dcd0931\")\n# │   inputs =\n# │    Dict{String, Any} with 2 entries:\n# │      \"IN2\" => 2\n# │      \"IN1\" => `in1`\n# │   outputs =\n# │    Dict{String, Any} with 1 entry:\n# └      \"OUT\" => \"out\"\n# inputs are: in1 and 2\n# outputs are: out\n# ┌ Info: 2025-03-04 22:31:12 Finished: Command Program\n# │   command_running = `echo inputs are: in1 and 2` & `echo outputs are: out`\n# │   run_id = Base.UUID(\"c30eed71-69ff-544b-a175-b6077dcd0931\")\n# │   inputs =\n# │    Dict{String, Any} with 2 entries:\n# │      \"IN2\" => 2\n# │      \"IN1\" => `in1`\n# │   outputs =\n# │    Dict{String, Any} with 1 entry:\n# └      \"OUT\" => \"out\"\n# (true, Dict{String, Any}(\"OUT\" => \"out\"))\n\n### run the program by submitting to JobSchedulers.jl\nprogram_job = submit!(p, IN1 = `in1`, IN2 = 2, OUT = \"out\", touch_run_id_file = false)\n# same results as `run`\n\n# get the returned result\nresult(program_job)\n# (true, Dict{String, Any}(\"OUT\" => \"out\"))","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"@submit also works with Programs:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"program_job2 = @submit IN1=`in1` IN2=2 OUT=\"out\" touch_run_id_file=false p","category":"page"},{"location":"manual/#Scheduler-settings","page":"Manual","title":"Scheduler settings","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Check the current status of scheduler:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"scheduler_status()\n# ┌ Info: Scheduler is running.\n# │   SCHEDULER_MAX_CPU = 32\n# │   SCHEDULER_MAX_MEM = \"169.6 GB\"\n# │   JOB_QUEUE.max_done = 10000\n# │   JOB_QUEUE.max_cancelled = 10000\n# │   SCHEDULER_TASK[] = Task (runnable) @0x00007fe205052e60\n# └   SCHEDULER_REACTIVATION_TASK[] = Task (runnable) @0x00007d4160031f50\n# :running","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Set the maximum CPU that the scheduler can use. If starting Julia with multi-threads, the maximum CPU is the number of default thread pool, excluding thread ID 1.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"set_scheduler_max_cpu()     # use all available CPUs\n# 32\nset_scheduler_max_cpu(4)    # use 4 CPUs\n# 4\nset_scheduler_max_cpu(0.5)  # use 50% of CPUs\n# 16","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Set the maximum RAM the scheduler can use:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"set_scheduler_max_mem()             # use 80% of total memory\n# 107792089088\n\nset_scheduler_max_mem(4GB)          # use 4GB memory\nset_scheduler_max_mem(4096MB)\nset_scheduler_max_mem(4194304KB)\nset_scheduler_max_mem(4294967296B)\n# 4294967296\n\nset_scheduler_max_mem(0.5)          # use 50% of total memory\n# 101166391296","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Set the maximum number of finished jobs:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"set_scheduler_max_job(max_done::Int = 10000, max_cancelled::Int = max_done)\n\nset_scheduler_max_job(10000)  # If number of finished jobs > 10000, \n                              #    the oldest ones will be removed.\n# 10000                       # It does not affect queuing, running, or failed jobs.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Set the previous setting in one function:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"set_scheduler(;\n    max_cpu = JobSchedulers.SCHEDULER_MAX_CPU,\n    max_mem = JobSchedulers.SCHEDULER_MAX_MEM,\n    max_job = JobSchedulers.JOB_QUEUE.max_done,\n    max_cancelled_job = JobSchedulers.JOB_QUEUE.max_cancelled_job,\n    update_second = JobSchedulers.SCHEDULER_UPDATE_SECOND\n)\n# ┌ Info: Scheduler is running.\n# │   SCHEDULER_MAX_CPU = 32\n# │   SCHEDULER_MAX_MEM = \"169.6 GB\"\n# │   JOB_QUEUE.max_done = 10000\n# │   JOB_QUEUE.max_cancelled = 10000\n# │   SCHEDULER_TASK[] = Task (runnable) @0x00007fe205052e60\n# └   SCHEDULER_REACTIVATION_TASK[] = Task (runnable) @0x00007d4160031f50\n# :running","category":"page"},{"location":"manual/#Backup","page":"Manual","title":"Backup","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Set backup file:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"set_scheduler_backup(\"/path/to/backup/file\")","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"JobSchedulers writes to the backup file at exit. If the file exists, scheduler settings and job queue will be recovered from it automatically. Recovered jobs are just for query, not run-able.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Stop backup and delete_old backup:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"set_scheduler_backup(delete_old=true)","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Backup immediately:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"backup()","category":"page"},{"location":"use_cases/#Use-Cases","page":"Use Cases","title":"Use Cases","text":"","category":"section"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"JobSchedulers.jl can used to glue commands in a pipeline/workflow, and can also be used in pure Julia functions.","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"The overhead of scheduling tasks is very low, and can be used to replace Threads.@threads for ... end. Scheduling 100,000 jobs can be done within 0.2 seconds. See more at section \"Overhead Benchmark\".","category":"page"},{"location":"use_cases/#Parallel-Nested-Loops","page":"Use Cases","title":"Parallel Nested Loops","text":"","category":"section"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"One of the many applications of scheduling systems is that it can be used as a drop-in replacement for nested multi-threaded loops that would otherwise be written with Threads.@threads.","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"Consider a simplified scenario where you want to calculate the maximum mean values of random samples of various lengths that have been generated by several distributions provided by the Distributions.jl package. The results should be collected into a DataFrame. We have the following function:","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"# julia -t 8,1\n\nusing Random, Distributions, StatsBase, DataFrames\n\nfunction f(dist, len, reps, σ)\n    v = Vector{Float64}(undef, len) # avoiding allocations\n    maximum(mean(rand!(dist, v)) for _ in 1:reps)/σ\nend","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"Let us consider the following probability distributions for numerical experiments, all of which have expected values equal to zero, and the following lengths of vectors:","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"dists = [Cosine, Epanechnikov, Laplace, Logistic, Normal, NormalCanon, PGeneralizedGaussian, SkewNormal, SkewedExponentialPower, SymTriangularDist]\nlens = [10, 20, 50, 100, 200, 500]","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"Using Threads.@threads those experiments could be parallelized as:","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"using Base.Threads\n\nfunction experiments_threads(dists, lens, K=1000)\n    res = DataFrame()\n    lck = ReentrantLock()\n    Threads.@threads for T in dists\n        dist = T()\n        σ = std(dist)\n        for L in lens\n            z = f(dist, L, K, σ)\n            Threads.lock(lck) do\n                push!(res, (;T, σ, L, z))\n            end\n        end\n    end\n    res\nend\n\nexperiments_threads(dists, lens, 1000)\n@time experiments_threads(dists, lens, 10000);\n#  7.096723 seconds (817 allocations: 107.594 KiB)\n#  7.116899 seconds (817 allocations: 107.594 KiB, 1 lock conflict)\n#  7.117008 seconds (817 allocations: 107.594 KiB)","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"Note that DataFrames.push! is not a thread safe operation and hence we need to utilize a locking mechanism in order to avoid two threads appending the DataFrame at the same time.","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"The same code could be rewritten in JobSchedulers as:","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"using JobSchedulers\n\nfunction experiments_jobschedulers(dists, lens, K=1000)\n    res = DataFrame()\n    for T in dists\n        dist = T()\n        σ = @submit std(dist)\n        for L in lens\n            z = @submit f(dist, L, K, result(σ))\n            push!(res, (;T, σ, L, z))\n        end\n    end\n    res.z = fetch.(res.z)\n    res.σ = fetch.(res.σ)\n    res\nend\n\nexperiments_jobschedulers(dists, lens, 1000)\n@time experiments_jobschedulers(dists, lens, 10000);\n#  3.834554 seconds (6.24 k allocations: 281.156 KiB)\n#  3.771652 seconds (6.30 k allocations: 281.750 KiB, 2 lock conflicts)\n#  3.746664 seconds (6.30 k allocations: 282.031 KiB)","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"In this code we have job interdependence. Firstly, we are calculating the standard deviation σ, and then we are using that value in the function f. Here, submit! wraps a task or a 0-argument function. Since submit! yields a Job rather than actual values, we need to use the result function to obtain those values. Because computing z requires completion of σ, we need to add argument dependency=σ to submit!. In the last, after all jobs are submitted, we use fetch to wait for each job to finish and return its value.","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"Also, note that contrary to the previous example, we do not need to implement locking as we are just pushing the Job results of submit! serially into the DataFrame (which is fast since submit! doesn't block).","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"The above use case scenario has been tested by running julia -t 8,1 (or with JULIA_NUM_THREADS=8,1 as environment variable), Julia version 1.11.3. The Threads.@threads code takes 7.1 seconds to run, while the JobSchedulers code, runs around 3.8 seconds, resulting in a 1.9x speedup.","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"info: Citation\nParallel Nested Loops was copied and edited from Dagger.jl's document. Most information are the same, except that JobSchedulers.jl was used.","category":"page"},{"location":"use_cases/#A-Workflow-Example-With-Pipelines.jl","page":"Use Cases","title":"A Workflow Example With Pipelines.jl","text":"","category":"section"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"Run prog_A with 2 threads and 4GB RAM.\nRun prog_B with 8 threads.\nAfter prog_A finished, run prog_C (2 threads).\nAfter prog_B and prog_C finished, run prog_D (12 threads)","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"The flowchart is like:","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"(Image: workflow flowchart)","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"The Julia code:","category":"page"},{"location":"use_cases/","page":"Use Cases","title":"Use Cases","text":"using JobSchedulers, Pipelines\n\nprog_A = CmdProgram(...)\nprog_B = JuliaProgram(...)\nprog_C = CmdProgram(...)\nprog_D = JuliaProgram(...)\n\njob_A = submit!(prog_A; A_args..., ncpu = 2, mem = 4GB)\n\njob_B = submit!(prog_B; B_args..., ncpu = 8)\n\njob_C = submit!(prog_C; C_args..., ncpu = 2,\n                dependency = job_A)\n\njob_D = submit!(prog_D; D_args..., ncpu = 12, \n                dependency = [PAST => job_B, job_C])\n\nwait_queue()","category":"page"},{"location":"#JobSchedulers.jl","page":"Home","title":"JobSchedulers.jl","text":"","category":"section"},{"location":"#Why-JobScheduler?","page":"Home","title":"Why JobScheduler?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We may find different tasks or programs use different CPU and memory. Some can run simultaneously, but some have to run sequentially. JobScheduler is stable, useful and powerful for task queuing and workload management, inspired by Slurm/PBS and Crontab.","category":"page"},{"location":"#Package-Features","page":"Home","title":"Package Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Job and task scheduler.\nLocal workload manager.\nSupport CPU, memory, run time management.\nSupport running a job at specific time, or a period after creating (schedule).\nSupport recurring/repetitive jobs using Cron-like schedule expressions.\nSupport deferring a job until specific jobs reach specific states (dependency).\nSupport automatic backup and reload.\nFancy progress meter in terminal.\n(Image: progress meter)","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JobSchedulers.jl can be installed using the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add JobSchedulers","category":"page"},{"location":"","page":"Home","title":"Home","text":"To use the package, type","category":"page"},{"location":"","page":"Home","title":"Home","text":"using JobSchedulers","category":"page"},{"location":"#Video","page":"Home","title":"Video","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This work was presented at JuliaCon 2023 as \"J Chuan, X Li. Pipelines & JobSchedulers for Computational Workflow Development.\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can watch the presentation here:","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: )","category":"page"},{"location":"API/#API","page":"API","title":"API","text":"","category":"section"},{"location":"API/#Const/Variables","page":"API","title":"Const/Variables","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"const B = 1\nconst KB = 1024\nconst MB = 1024KB\nconst GB = 1024MB\nconst TB = 1024GB\n\nconst QUEUING = :queuing\nconst RUNNING = :running\nconst DONE = :done\nconst FAILED = :failed\nconst CANCELLED = :cancelled\nconst PAST = :past # super set of DONE, FAILED, CANCELLED\n\nconst cron_none = Cron(:none)\n\nconst SCHEDULER_TASK = Base.RefValue{Task}()\nconst SCHEDULER_REACTIVATION_TASK = Base.RefValue{Task}()","category":"page"},{"location":"API/#Job","page":"API","title":"Job","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"Job\nsubmit!\n@submit\ncancel!\nresult\nfetch(::Job)\nisqueuing\nisrunning\nisdone\niscancelled\nisfailed\nispast","category":"page"},{"location":"API/#JobSchedulers.Job","page":"API","title":"JobSchedulers.Job","text":"Job(command::Base.AbstractCmd; stdout=nothing, stderr=nothing, append::Bool=false, kwargs...)\nJob(f::Function; kwargs...)\nJob(task::Task; kwargs...)\n\nArguments\n\ncommand::Base.AbstractCmd: the command to run.\nf::Function: the function to run without any arguments, like f().\ntask::Task: the task to run. Eg: @task(1+1).\n\nCommon Keyword Arguments (kwargs...)\n\nname::String = \"\": job name.\nuser::String = \"\": user that job belongs to.\nncpu::Real = 1.0: number of CPU this job is about to use (can be Float64, eg: 1.5 will use 150% CPU).\nmem::Integer = 0: number of memory this job is about to use (supports TB, GB, MB, KB, B=1).\nschedule_time::Union{DateTime,Period} = DateTime(0): The expected time to run.\ndependency: defer job until specified jobs reach specified state (QUEUING, RUNNING, DONE, FAILED, CANCELLED, PAST). PAST is the super set of DONE, FAILED, CANCELLED, which means the job will not run in the future. Eg: DONE => job, [DONE => job1; PAST => job2].\n\ninfo: Dependency\nThe default state is DONE, so DONE => job can be simplified to job.   To be compatible with old versions, you can also use job id (Int): [DONE => job.id].\n\nwall_time::Period = Year(1): wall clock time limit. Jobs will be terminated after running for this period.\npriority::Int = 20: lower means higher priority.\ncron::Cron = Cron(:none): job recurring at specfic date and time. See more at Cron.\nuntil::Union{DateTime,Period} = DateTime(9999,1,1): stop job recurring until date and time.\n\nExperimental Keyword Arguments - Output Redirection:\n\nstdout=nothing: redirect stdout to the file.\nstderr=nothing: redirect stderr to the file.\nappend::Bool=false: append the stdout or stderr or not.\n\nnote: Note\nRedirecting in Julia are not thread safe, so unexpected redirection might be happen if you are running programs in different Tasks simultaneously (multi-threading).\n\nSee also submit!, @submit, Cron\n\n\n\n\n\n","category":"type"},{"location":"API/#JobSchedulers.submit!","page":"API","title":"JobSchedulers.submit!","text":"submit!(job::Job)\nsubmit!(args_of_Job...; kwargs_of_Job...)\n\nSubmit the job to queue. \n\nsubmit!(Job(...)) can be simplified to submit!(...). They are equivalent.\n\nSee also Job, @submit\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.@submit","page":"API","title":"JobSchedulers.@submit","text":"@submit [option=value]... expr\n\nSubmit a job from expr. If a Job is explicitly shown in expr, DONE => job will be automatically added to the dependency list. \n\nexpr: any type of Expression is supported. \noption = value: kwargs of Job. If expr is parsed to be a Pipelines.Program, options also include its inputs, outputs and run kwargs.\n\nSee also Job, submit!\n\nExample\n\nj = @submit 1+1\nwait(j)\n@assert result(j) == 2\n\n# you can use any keyword arguments that `Job` supports, such as `name`, `ncpu`:\nj_2sec = @submit name = \"run after 2 sec\" begin sleep(2); 32 end\n\n# because `j_2sec isa Job`, `DONE => j_2sec` is pushed to `j2.dependency`.\nj2 = @submit mem=2KB begin\n    1 + result(j_2sec)\nend\n\nwait(j2)\n@assert result(j2) == 1 + 32\n\n# you can also manually add dependencies not in the `expr`:\nj3 = @submit dependency = [PAST => j] println(\"j3 finished. result of j2 = \", result(j2))\n\n# Note: j3.dependency might be empty after submit, because JobScheduler will remove jobs that reached their states in the dependency list.\n\nwarning: Only explicit jobs can be automatically added to dependency\n@submit cannot know the elements in a container, so it is unable to walk through and add Job dependencies in a container.jobs = Job[]  # the job container\nfor i in 1:2\n    push!(jobs, @submit begin sleep(30);i end) # 10 jobs will be added to `jobs`\nend\n\nx = 0\nj_something_wrong = @submit for j in jobs\n    # have to use global x\n    global x += result(j)\nend\n# ┌ Warning: Getting result from a running job: returned value might be unexpected.\n# └ @ JobSchedulers ~/projects/JobSchedulers.jl/src/jobs.jl:318\n\nresult(j_something_wrong)\n# MethodError(+, (nothing, nothing), 0x0000000000007b16)To avoid it, we can       (1) use submit!, or      (2) explicitly add dependency = jobs to @submit.x = 0\nj_ok = submit!(dependency = jobs) do\n    for j in jobs\n        # have to use global x\n        global x += result(j)\n    end\nend\nwait(j_ok)\n@assert x == 55\n\nx = 100\nj_ok_too = @submit dependency = jobs for j in jobs\n    # have to use global x\n    global x += result(j)\nend\nwait(j_ok_too)\n@assert x == 155\n\n\n\n\n\n","category":"macro"},{"location":"API/#JobSchedulers.cancel!","page":"API","title":"JobSchedulers.cancel!","text":"cancel!(job::Job)\n\nCancel job, stop queuing or running.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.result","page":"API","title":"JobSchedulers.result","text":"result(job::Job)\n\nReturn the result of job. If the job is not done, a warning message will also show.\n\n\n\n\n\n","category":"function"},{"location":"API/#Base.fetch-Tuple{Job}","page":"API","title":"Base.fetch","text":"fetch(x::Job)\n\nWait for a Job to finish, then return its result value. If the task fails with an exception, a TaskFailedException (which wraps the failed task) is thrown.\n\ncompat: Compat\nfetch(x::Job) is available from JobSchedulers v0.10.2.\n\n\n\n\n\n","category":"method"},{"location":"API/#JobSchedulers.isqueuing","page":"API","title":"JobSchedulers.isqueuing","text":"isqueuing(j::Job) :: Bool\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.isrunning","page":"API","title":"JobSchedulers.isrunning","text":"isrunning(j::Job) :: Bool\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.isdone","page":"API","title":"JobSchedulers.isdone","text":"isdone(j::Job) :: Bool\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.iscancelled","page":"API","title":"JobSchedulers.iscancelled","text":"iscancelled(j::Job) :: Bool\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.isfailed","page":"API","title":"JobSchedulers.isfailed","text":"isfailed(j::Job) :: Bool\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.ispast","page":"API","title":"JobSchedulers.ispast","text":"ispast(j::Job) :: Bool = j.state === DONE || j.state === CANCELLED || j.state === FAILED\n\n\n\n\n\n","category":"function"},{"location":"API/#Cron:-Job-Recur/Repeat","page":"API","title":"Cron: Job Recur/Repeat","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"Cron\nJobSchedulers.cron_value_parse\nDates.tonext(::DateTime, ::Cron)","category":"page"},{"location":"API/#JobSchedulers.Cron","page":"API","title":"JobSchedulers.Cron","text":"Cron(second, minute, hour, day_of_month, month, day_of_week)\nCron(;\n    second = 0,\n    minute = '*',\n    hour = '*',\n    day_of_month = '*',\n    month = '*',\n    day_of_week = '*',\n)\n\nCron stores the schedule of a repeative Job, implemented according to Linux-based crontab(5) table.\n\nJobs are executed when the second, minute, hour and month fields match the current time. If neither day_of_month nor day_of_week starts with *, cron takes the union (∪) of their values day_of_month ∪ day_of_week. Otherwise cron takes the intersection (∩) of their values day_of_month ∩ day_of_week.\n\nWhen an argument is an Int:\n\nField Allowed values\nsecond 0-59\nminute 0-59\nhour 0-23\nday_of_month 1-31\nmonth 1-12\nday_of_week 1-7 (1 is Monday)\n\ncompat: Diff between Linux crontab\nTypical Linux distributions do not have second filed as JobSchedulers.\nSunday is only coded 7 in JobSchedulers, while it is 0 or 7 in Linux, so the behaviors like day_of_week = \"*/2\" are different in two systems.\nFrom JobSchedulers v0.11, Cron has been rewritten based on the standard crontab, including its bug described here.\n\nWhen an argument is a String or Char:\n\nAn argument may be an asterisk (*), which always stands for first-last.\n\nRanges of numbers are allowed. Ranges are two numbers separated with a hyphen. The specified range is inclusive. For example, 8-11 for an hours entry specifies execution at hours 8, 9, 10 and 11.\n\nLists are allowed. A list is a set of numbers (or ranges) separated by commas. Examples: \"1,2,5,9\", \"0-4,8-12\".\n\nStep values can be used in conjunction with ranges. Following a range with /<number> specifies skips of the number's value through the range. For example, \"0-23/2\" can be used in the hour argument to specify Job execution every other hour (the alternative is \"0,2,4,6,8,10,12,14,16,18,20,22\"). Steps are also permitted after an asterisk, so if you want to say every two hours, just use \"*/2\".\n\nWhen an argument is a Vector:\n\nVector works like lists mentioned above. For example, [1,2,5,9] is equivalent to \"1,2,5,9\".\n\nWhen an argument is a UInt64:\n\nUInt64 is the internal type of Cron fileds. All the previous types will be converted to a UInt64 bit array. The start index of the bit array is 0. Bits outside of the allowed values (see the table above) are ignored.\n\n\n\n\n\nCron(special::Symbol)\n\nInstead of the six arguments of Cron, one of the following special symbols may appear instead:\n\nspecial Meaning\n:yearly Run once a year, Cron(0,0,0,1,1,0)\n:annually (same as :yearly)\n:monthly Run once a month, Cron(0,0,0,1,'*','*')\n:weekly Run once a week, Cron(0,0,0,'*','*',1)\n:daily Run once a day, Cron(0,0,0,'*','*','*')\n:midnight (same as :daily)\n:hourly Run once an hour, Cron(0,0,'*','*','*','*')\n:none Never repeat, Cron(0,0,0,0,0,0)\n\nCaution: Linux crontab's special :reboot is not supported here.\n\nTo run every minute, just use Cron().\n\n\n\n\n\n","category":"type"},{"location":"API/#JobSchedulers.cron_value_parse","page":"API","title":"JobSchedulers.cron_value_parse","text":"cron_value_parse(value::UInt64)\ncron_value_parse(value::Signed)\ncron_value_parse(value::AbstractString)\ncron_value_parse(value::Char)\ncron_value_parse(value::Vector)\ncron_value_parse(*) = cron_value_parse('*')\n\nParse crontab-like value to UInt64. See details: Cron.\n\n\n\n\n\n","category":"function"},{"location":"API/#Dates.tonext-Tuple{DateTime, Cron}","page":"API","title":"Dates.tonext","text":"Dates.tonext(dt::DateTime, c::Cron; same::Bool = false) -> Union{DateTime, Nothing}\nDates.tonext(t::Time, c::Cron; same::Bool = false) -> Time\nDates.tonext(d::Date, c::Cron; same::Bool = false, limit::Date = d + Day(3000)) -> Union{DateTime, Nothing}\n\nAdjust date or time to the next one corresponding to c::Cron. Setting same=true allows the current date or time to be considered as the next one, allowing for no adjustment to occur.\n\n\n\n\n\n","category":"method"},{"location":"API/#Queue","page":"API","title":"Queue","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"queue\nall_queue\njob_query","category":"page"},{"location":"API/#JobSchedulers.queue","page":"API","title":"JobSchedulers.queue","text":"queue(; all::Bool = false)    -> Vector{Job}\nqueue(state::Symbol )         -> Vector{Job}\nqueue(needle)                 -> Vector{Job}\nqueue(state::Symbol , needle) -> Vector{Job}\nqueue(needle, state::Symbol ) -> Vector{Job}\nqueue(id::Integer)            -> Job\n\nall::Bool: if true, get all jobs. if false, get only running and queuing jobs.\nstate::Symbol: get jobs with a specific state, including :all, QUEUING, RUNNING, DONE, FAILED, CANCELLED, PAST.\nPAST is the superset of DONE, FAILED, CANCELLED.\nneedle::Union{AbstractString,AbstractPattern,AbstractChar}: get jobs if they contain needle in their name or user.\nid::Integer: get the job with the specific id.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.all_queue","page":"API","title":"JobSchedulers.all_queue","text":"all_queue()\nall_queue(id::Integer)\nall_queue(state::Symbol)\nall_queue(needle::Union{AbstractString,AbstractPattern,AbstractChar})\n\nstate::Symbol: get jobs with a specific state, including :all, QUEUING, RUNNING, DONE, FAILED, CANCELLED, PAST.\nPAST is the superset of DONE, FAILED, CANCELLED.\nneedle::Union{AbstractString,AbstractPattern,AbstractChar}: get jobs if they contain needle in their name or user.\nid::Integer: get the job with the specific id.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.job_query","page":"API","title":"JobSchedulers.job_query","text":"job_query_by_id(id::Integer)\n\nSearch job by job.id in the queue.\n\nReturn job::Job if found, nothing if not found.\n\n\n\n\n\n","category":"function"},{"location":"API/#Wait-For-Jobs","page":"API","title":"Wait For Jobs","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"wait_queue\nwait(::Job)","category":"page"},{"location":"API/#JobSchedulers.wait_queue","page":"API","title":"JobSchedulers.wait_queue","text":"wait_queue(;show_progress::Bool = false, exit_num_jobs::Int = 0)\n\nWait for all jobs in queue() become finished.\n\nshow_progress = true, job progress will show.\nexit_num_jobs::Int: exit when queue() has less than Int number of jobs. It is useful to ignore some jobs that are always running or recurring.\n\nSee also: queue_progress.\n\n\n\n\n\n","category":"function"},{"location":"API/#Base.wait-Tuple{Job}","page":"API","title":"Base.wait","text":"wait(j::Job)\nwait(js::Vector{Job})\n\nWait for the job(s) to be finished.\n\n\n\n\n\n","category":"method"},{"location":"API/#Scheduler-Settings","page":"API","title":"Scheduler Settings","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"set_scheduler\nset_scheduler_max_cpu\nset_scheduler_max_mem\nset_scheduler_max_job\nJobSchedulers.destroy_unnamed_jobs_when_done\nJobSchedulers.set_group_seperator\nJobSchedulers.GROUP_SEPERATOR","category":"page"},{"location":"API/#JobSchedulers.set_scheduler","page":"API","title":"JobSchedulers.set_scheduler","text":"set_scheduler(;\n    max_cpu::Real = JobSchedulers.SCHEDULER_MAX_CPU,\n    max_mem::Real = JobSchedulers.SCHEDULER_MAX_MEM,\n    max_job::Int = JobSchedulers.JOB_QUEUE.max_done,\n    max_cancelled_job::Int = JobSchedulers.JOB_QUEUE.max_cancelled_job\n)\n\nmax_job: the number of jobs done. If number of jobs exceed 1.5*NUMBER, old jobs will be delete.\nmax_cancelled_job: the number of cancelled jobs. If number of jobs exceed 1.5*NUMBER, old jobs will be delete.\n\nSee details: set_scheduler_max_cpu,  set_scheduler_max_mem,  set_scheduler_max_job\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.set_scheduler_max_cpu","page":"API","title":"JobSchedulers.set_scheduler_max_cpu","text":"set_scheduler_max_cpu(ncpu::Int = default_ncpu())\nset_scheduler_max_cpu(percent::Float64)\n\nSet the maximum CPU (thread) the scheduler can use. If starting Julia with multiple threads in the default thread pool, the maximum CPU is the number of tids in the default thread pool not equal to 1.\n\nExample\n\nset_scheduler_max_cpu()     # use all available CPUs\nset_scheduler_max_cpu(4)    # use 4 CPUs\nset_scheduler_max_cpu(0.5)  # use 50% of CPUs\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.set_scheduler_max_mem","page":"API","title":"JobSchedulers.set_scheduler_max_mem","text":"set_scheduler_max_mem(mem::Integer = default_mem())\nset_scheduler_max_mem(percent::AbstractFloat)\n\nSet the maximum RAM the scheduler can use.\n\nExample\n\nset_scheduler_max_mem()             # use 80% of total memory\n\nset_scheduler_max_mem(4GB)          # use 4GB memory\nset_scheduler_max_mem(4096MB)\nset_scheduler_max_mem(4194304KB)\nset_scheduler_max_mem(4294967296B)\n\nset_scheduler_max_mem(0.5)          # use 50% of total memory\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.set_scheduler_max_job","page":"API","title":"JobSchedulers.set_scheduler_max_job","text":"set_scheduler_max_job(max_done::Int = 10000, max_cancelled::Int = max_done)\n\nSet the number of finished jobs. If number of jobs exceed 1.5*NUMBER, old jobs will be delete.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.destroy_unnamed_jobs_when_done","page":"API","title":"JobSchedulers.destroy_unnamed_jobs_when_done","text":"JobSchedulers.destroy_unnamed_jobs_when_done(b::Bool)\n\ncompat: New in v0.10\nBefore v0.10, all jobs will be saved to queue. However, from v0.10, unnamed jobs (job.name == \"\") will not be saved if it successfully ran. If you want to save unnamed jobs, you can set using JobSchedulers.destroy_unnamed_jobs_when_done(false).\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.set_group_seperator","page":"API","title":"JobSchedulers.set_group_seperator","text":"set_group_seperator(group_seperator::Regex) = global GROUP_SEPERATOR = group_seperator\n\nSet the group seperator. Group seperator is used to group the names of Jobs. Used when display the progress meter using wait_queue(show_progress=true)\n\nDefault is r\": *\".\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.GROUP_SEPERATOR","page":"API","title":"JobSchedulers.GROUP_SEPERATOR","text":"GROUP_SEPERATOR::Regex = r\": *\"\n\nGroup seperator is used to group the names of Jobs. Used when display the progress meter using wait_queue(show_progress=true)\n\nTo set it, use set_group_seperator(group_seperator::Regex).\n\n\n\n\n\n","category":"constant"},{"location":"API/#Scheduler-Control","page":"API","title":"Scheduler Control","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"Scheduler is automatically started, so it is not necessary to start/stop it.","category":"page"},{"location":"API/","page":"API","title":"API","text":"scheduler_status\nscheduler_start\nscheduler_stop","category":"page"},{"location":"API/#JobSchedulers.scheduler_status","page":"API","title":"JobSchedulers.scheduler_status","text":"scheduler_status() :: Symbol\n\nPrint the settings and status of job scheduler. Return :not_running or :running.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.scheduler_start","page":"API","title":"JobSchedulers.scheduler_start","text":"scheduler_start()\n\nStart the job scheduler.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.scheduler_stop","page":"API","title":"JobSchedulers.scheduler_stop","text":"scheduler_stop()\n\nStop the job scheduler.\n\n\n\n\n\n","category":"function"},{"location":"API/#Optimize-CPU-Usage","page":"API","title":"Optimize CPU Usage","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"solve_optimized_ncpu","category":"page"},{"location":"API/#JobSchedulers.solve_optimized_ncpu","page":"API","title":"JobSchedulers.solve_optimized_ncpu","text":"solve_optimized_ncpu(default::Int; \n    ncpu_range::UnitRange{Int} = 1:total_cpu, \n    njob::Int = 1, \n    total_cpu::Int = JobSchedulers.SCHEDULER_MAX_CPU, \n    side_jobs_cpu::Int = 0)\n\nFind the optimized number of CPU for a job.\n\ndefault: default ncpu of the job.\nncpu_range: the possible ncpu range of the job.\nnjob: number of the same job.\ntotal_cpu: the total CPU that can be used by JobSchedulers.\nside_jobs_cpu: some small jobs that might be run when the job is running, so the job won't use up all of the resources and stop small tasks.\n\n\n\n\n\n","category":"function"},{"location":"API/#Backup","page":"API","title":"Backup","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"set_scheduler_backup\nbackup","category":"page"},{"location":"API/#JobSchedulers.set_scheduler_backup","page":"API","title":"JobSchedulers.set_scheduler_backup","text":"set_scheduler_backup(\n    filepath::AbstractString = \"\";\n    migrate::Bool = false,\n    delete_old::Bool = false,\n    recover_settings::Bool = true,\n    recover_queue::Bool = true\n)\n\nSet the backup file of job scheduler.\n\nIf filepath was set to \"\", stop backup at exit.\n\nIf filepath was set to an existing file, recover_settings or recover_queue from filepath immediately.\n\nIf filepath was set to a new file, the backup file will be created at exit.\n\nIf migrate=true and the old JobSchedulers.SCHEDULER_BACKUP_FILE exists, the old backup file will be recovered before recovering from filepath.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.backup","page":"API","title":"JobSchedulers.backup","text":"backup()\n\nManually backup job scheduler settings and queues. The function is automatically triggered at exit.\n\n\n\n\n\n","category":"function"},{"location":"API/#Internal","page":"API","title":"Internal","text":"","category":"section"},{"location":"API/#Internal-Scheduling","page":"API","title":"Internal - Scheduling","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"JobSchedulers.JobQueue\nJobSchedulers.scheduler()\nJobSchedulers.istaskfailed2\nJobSchedulers.unsafe_run!\nJobSchedulers.unsafe_cancel!\nJobSchedulers.unsafe_update_state!\nJobSchedulers.is_dependency_ok\nJobSchedulers.set_scheduler_while_loop\nJobSchedulers.get_priority\nJobSchedulers.get_thread_id\nJobSchedulers.date_based_on\nJobSchedulers.next_recur_job","category":"page"},{"location":"API/#JobSchedulers.JobQueue","page":"API","title":"JobSchedulers.JobQueue","text":"JobQueue(; max_done::Int = 10000, max_cancelled::Int = 10000)\nmutable struct JobQueue\n    const queuing::SortedDict{Int,LinkedJobList,Base.Order.ForwardOrdering}  # priority => Job List\n    const queuing_0cpu::LinkedJobList              # ncpu = 0, can run immediately\n    const future::LinkedJobList                    # all jobs with schedule_time > now()\n    const running::LinkedJobList        const running::Vector{Job}\n    const done::Vector{Job}\n    const failed::Vector{Job}\n    const cancelled::Vector{Job}\n    max_done::Int\n    max_cancelled::Int\n    const lock_queuing::ReentrantLock\n    const lock_running::ReentrantLock\n    const lock_past::ReentrantLock\nend\n\n\n\n\n\n","category":"type"},{"location":"API/#JobSchedulers.scheduler-Tuple{}","page":"API","title":"JobSchedulers.scheduler","text":"scheduler()\n\nThe function of running Job's scheduler. It needs to be called by scheduler_start(), rather than calling directly.\n\n\n\n\n\n","category":"method"},{"location":"API/#JobSchedulers.istaskfailed2","page":"API","title":"JobSchedulers.istaskfailed2","text":"istaskfailed2(t::Task)\n\nExtend Base.istaskfailed to fit Pipelines and JobSchedulers packages, which will return a StackTraceVector in t.result, while Base considered it as :done. The function checks the situation and modifies the real task status and other properties.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.unsafe_run!","page":"API","title":"JobSchedulers.unsafe_run!","text":"unsafe_run!(job::Job, current::DateTime=now()) :: Bool\n\nJump the queue and run job immediately, no matter what other jobs are running or waiting. If successful initiating to run, return true, else false. \n\nCaution: it will not trigger scheduler_need_action().\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.unsafe_cancel!","page":"API","title":"JobSchedulers.unsafe_cancel!","text":"unsafe_cancel!(job::Job, current::DateTime=now())\n\nCaution: it is unsafe and should only be called within lock. Do not call from other module.\n\nCaution: it will not trigger scheduler_need_action().\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.unsafe_update_state!","page":"API","title":"JobSchedulers.unsafe_update_state!","text":"unsafe_update_state!(job::Job)\n\nUpdate the state of job from job.task when job.state === :running.\n\nIf a repeative job is PAST, submit a new job.\n\nCaution: it is unsafe and should only be called within lock.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.is_dependency_ok","page":"API","title":"JobSchedulers.is_dependency_ok","text":"is_dependency_ok(job::Job)::Bool\n\nCaution: run it within lock only.\n\nAlgorithm: Break while loop when found dep not ok, and change job._dep_check_id to the current id.\n\nIf dep is provided as Integer, query Integer for job and then replace Integer with the job.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.set_scheduler_while_loop","page":"API","title":"JobSchedulers.set_scheduler_while_loop","text":"set_scheduler_while_loop(b::Bool)\n\nif set to false, the scheduler will stop.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.get_priority","page":"API","title":"JobSchedulers.get_priority","text":"get_priority(job::Job) = job.priority\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.get_thread_id","page":"API","title":"JobSchedulers.get_thread_id","text":"get_thread_id(job::Job) = job._thread_id\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.date_based_on","page":"API","title":"JobSchedulers.date_based_on","text":"date_based_on(c::Cron) -> Symbol\n\nWhether date of c is based on :day_of_week, :day_of_month, :union, :intersect, :everyday, :none, or :undefined.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.next_recur_job","page":"API","title":"JobSchedulers.next_recur_job","text":"next_recur_job(j::Job) -> Union{Job, Nothing}\n\nBased on j.cron and j.until, return a new recurring Job or nothing.\n\n\n\n\n\n","category":"function"},{"location":"API/#Internal-Progress-Meter","page":"API","title":"Internal - Progress Meter","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"note: Note\nTo display a progress meter, please use wait_queue(show_progress = true).","category":"page"},{"location":"API/","page":"API","title":"API","text":"JobSchedulers.JobGroup\nJobSchedulers.get_group\nJobSchedulers.progress_bar\nJobSchedulers.queue_progress\nJobSchedulers.view_update\nJobSchedulers.PROGRESS_METER\nJobSchedulers.update_group_state!\nJobSchedulers.init_group_state!()","category":"page"},{"location":"API/#JobSchedulers.JobGroup","page":"API","title":"JobSchedulers.JobGroup","text":"mutable struct JobGroup\n    name::String\n    total::Int\n    queuing::Int\n    running::Int\n    done::Int\n    failed::Int\n    cancelled::Int\nend\n\nJobGroup is computed when displaying a progress meter.\n\n\n\n\n\n","category":"type"},{"location":"API/#JobSchedulers.get_group","page":"API","title":"JobSchedulers.get_group","text":"get_group(job::Job, group_seperator = GROUP_SEPERATOR)\nget_group(name::AbstractString, group_seperator = GROUP_SEPERATOR)\n\nReturn nested_group_names::Vector{String}. \n\nEg: If job.name is \"A: B: 1232\", return [\"A\", \"A: B\", \"A: B: 1232\"]\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.progress_bar","page":"API","title":"JobSchedulers.progress_bar","text":"progress_bar(percent::Float64, width::Integer = 20)\n\nReturn ::String for progress bar whose char length is width.\n\npercent: range from 0.0 - 1.0, or to be truncated.\nwidth: should be > 3. If <= 10, percentage will not show. If > 10, percentage will show.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.queue_progress","page":"API","title":"JobSchedulers.queue_progress","text":"queue_progress(;remove_tmp_files::Bool = true, kwargs...)\nqueue_progress(stdout_tmp::IO, stderr_tmp::IO;\ngroup_seperator = GROUP_SEPERATOR, wait_second_for_new_jobs::Int = 1, loop::Bool = true, exit_num_jobs::Int = 0)\n\ngroup_seperator: delim to split (job::Job).name to group and specific job names.\nwait_second_for_new_jobs::Int: if auto_exit, and all jobs are PAST, not quiting queue_progress immediately but wait for a period. If new jobs are submitted, not quiting queue_progress.\nloop::Bool: if false, only show the current progress and exit. \nexit_num_jobs::Int: exit when queue() has less than Int number of jobs. It is useful to ignore some jobs that are always running or recurring.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.view_update","page":"API","title":"JobSchedulers.view_update","text":"view_update(h, w; row = 1, groups_shown::Vector{JobGroup} = JobGroup[], is_in_terminal::Bool = true, is_interactive = true, group_seperator_at_begining = Regex(\"^\" * GROUP_SEPERATOR.pattern))\n\nUpdate the whole screen view.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.PROGRESS_METER","page":"API","title":"JobSchedulers.PROGRESS_METER","text":"Bool. Showing progress meter? Related to progress computation and display. true when waitqueue(showprogress=true)\n\n\n\n\n\n","category":"constant"},{"location":"API/#JobSchedulers.update_group_state!","page":"API","title":"JobSchedulers.update_group_state!","text":"update_group_state!(job::Job)\n\nThis should only be called if JobSchedulers.PROGRESS_METER == true. Update the job's group state, which will be used in Progress Meter.\n\n\n\n\n\n","category":"function"},{"location":"API/#JobSchedulers.init_group_state!-Tuple{}","page":"API","title":"JobSchedulers.init_group_state!","text":"init_group_state!()\n\nPrepare group state for existing jobs \n\n\n\n\n\n","category":"method"},{"location":"API/#Internal-Const/Variable","page":"API","title":"Internal - Const/Variable","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"JobSchedulers.THREAD_POOL\nJobSchedulers.SINGLE_THREAD_MODE\nJobSchedulers.TIDS","category":"page"},{"location":"API/#JobSchedulers.THREAD_POOL","page":"API","title":"JobSchedulers.THREAD_POOL","text":"const THREAD_POOL = Base.RefValue{Channel{Int}}()\n\nDefined in __init__().\n\nIf version > 1.9, THREAD_POOL contains only tids in Threads.threadpooltids(:default).\n\nAlso, the thread 1 is reserved for JobScheduler.\n\n\n\n\n\n","category":"constant"},{"location":"API/#JobSchedulers.SINGLE_THREAD_MODE","page":"API","title":"JobSchedulers.SINGLE_THREAD_MODE","text":"const SINGLE_THREAD_MODE = Base.RefValue{Bool}()\n\nDefined in __init__(). Whether Threads.threadpooltids(:default) are empty or == [1].\n\n\n\n\n\n","category":"constant"},{"location":"API/#JobSchedulers.TIDS","page":"API","title":"JobSchedulers.TIDS","text":"const TIDS = Vector{Int}()\n\nDefined in __init__(). All tids in the default thread pool, excluding tid 1.\n\n\n\n\n\n","category":"constant"},{"location":"API/","page":"API","title":"API","text":"const SCHEDULER_ACTION = Base.RefValue{Channel{Int}}()  # defined in __init__()\nconst SCHEDULER_ACTION_LOCK = ReentrantLock()\nconst SCHEDULER_PROGRESS_ACTION = Base.RefValue{Channel{Int}}()  # defined in __init__()\n\nSCHEDULER_MAX_CPU::Int = -1              # set in __init__\nSCHEDULER_MAX_MEM::Int64 = Int64(-1)     # set in __init__\nSCHEDULER_UPDATE_SECOND::Float64 = 0.05  # set in __init__\n\nconst JOB_QUEUE = JobQueue(; max_done = JOB_QUEUE_MAX_LENGTH,  max_cancelled = max_done = JOB_QUEUE_MAX_LENGTH)\n\nSCHEDULER_BACKUP_FILE::String = \"\"\n\nSCHEDULER_WHILE_LOOP::Bool = true\n\nSLEEP_HANDELED_TIME::Int = 10\n\nDESTROY_UNNAMED_JOBS_WHEN_DONE::Bool = true\n\nconst ALL_JOB_GROUP = JobGroup(\"ALL JOBS\")\nconst JOB_GROUPS = OrderedDict{String, JobGroup}()\nconst OTHER_JOB_GROUP = JobGroup(\"OTHERS\")","category":"page"}]
}
